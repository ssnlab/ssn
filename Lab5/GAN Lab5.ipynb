{"cells":[{"cell_type":"markdown","source":["**TASK** Recap:\n","\n","- Jak działa perceptron?\n","- Jaka jest podstawowa operacja podczas propagacji informacji w przód w Sieci Feed Forward?\n","- Po co są funkcje aktywacji w sieciach neuronowych?\n","- Jakie są ograniczenia uczenia SSN metodą Stochastycznego Spadku wzdłuż gradientu?\n","- Co to są warsty Dropout i BatchNormalization i po co się je stosuje w sieciach neuronowych?\n","- Czym charakteryzują się neuronowe sieci konwolucyjne?\n","- Co to jest operacja splotu?\n","- Czym charakteryzują się neuronowe sieci rekurencyjne?\n","- Jakie istnieją metody poprawy skuteczności modeli rekurencyjnych w przetwarzaniu języka naturalnego?"],"metadata":{"id":"fsrq30vVkhvp"}},{"cell_type":"markdown","metadata":{"id":"EFwSaNB8jF7s"},"source":["<style>\n","td {\n","  text-align: center;\n","}\n","\n","th {\n","  text-align: center;\n","}\n","</style>"]},{"cell_type":"markdown","source":["## What are GANs?\n","[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A *generator* (\"the artist\") learns to create images that look real, while a *discriminator* (\"the art critic\") learns to tell real images apart from fakes.\n","\n","![A diagram of a generator and discriminator](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gan1.png?raw=1)\n","\n","During training, the *generator* progressively becomes better at creating images that look real, while the *discriminator* becomes better at telling them apart. The process reaches equilibrium when the *discriminator* can no longer distinguish real images from fakes.\n","\n","![A second diagram of a generator and discriminator](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gan2.png?raw=1)\n","\n"],"metadata":{"id":"WhJNAFa4k8eL"}},{"cell_type":"code","source":["# To generate GIFs\n","!pip install imageio\n","!pip install git+https://github.com/tensorflow/docs"],"metadata":{"id":"NiLoSTVWk834"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","import imageio\n","import matplotlib.pyplot as plt\n","from functools import partial\n","import numpy as np\n","import os\n","import PIL\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","import time\n","import tensorflow as tf\n","import gdown\n","from zipfile import ZipFile\n","\n","from IPython import display"],"metadata":{"id":"gpK_xIfQlBKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generacja twarzy z użyciem sieci GAN i danych celeb."],"metadata":{"id":"q-4xLSY8bnGa"}},{"cell_type":"markdown","source":["Pobieranie danych. To jest duży zbiór danych, nie będziemy używać całego zbioru do treningu bo nie mamy wystarczających zasobów.\n","\n","Do póżniejszej części zadania można usunąć ten plik z pamięci."],"metadata":{"id":"55oioSLha_mi"}},{"cell_type":"code","source":["os.makedirs(\"celeba_gan\")\n","\n","url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n","output = \"celeba_gan/data.zip\"\n","gdown.download(url, output, quiet=True)\n","\n","with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n","    zipobj.extractall(\"celeba_gan\")\n"],"metadata":{"id":"NV-nWyLY54Il"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Stworzenie obiektu Dataset do uczenia w Tensorflow."],"metadata":{"id":"gqkUqM-XbXAn"}},{"cell_type":"code","source":["dataset = keras.utils.image_dataset_from_directory(\n","    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=64\n",")\n","dataset = dataset.map(lambda x: x / 255.0)\n"],"metadata":{"id":"DJ2ONUbC54LP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Stworzenie próbki danych treningowych jako część oryginalnego zbioru danych."],"metadata":{"id":"SR047vY0be16"}},{"cell_type":"code","source":["dim = lambda x: x[:640, ...]\n","\n","train_dataset = dataset.map(dim)\n","\n","del dataset"],"metadata":{"id":"Qwb5vAiP1-sU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Wizualizacja przykładowej twarzy z zbioru danych"],"metadata":{"id":"NOjnlFKmfXzQ"}},{"cell_type":"code","source":["for x in train_dataset:\n","    plt.axis(\"off\")\n","    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n","    break\n"],"metadata":{"id":"LdhEJKxX6ZrL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model generatora: bierze jako wejście wektor wartości rzeczywistych (random noise) i tworzy obraz używając kombinacji warst liniowych i konwolucyjnych."],"metadata":{"id":"SjvFsrbQfbnb"}},{"cell_type":"code","source":["def make_generator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(16*16*128, use_bias=False, input_shape=(100,)))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Reshape((16, 16, 128)))\n","    assert model.output_shape == (None, 16, 16, 128)  # Note: None is the batch size\n","\n","    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n","    assert model.output_shape == (None, 32, 32, 128)\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.LeakyReLU())\n","\n","    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n","    assert model.output_shape == (None, 64, 64, 3)\n","\n","    return model"],"metadata":{"id":"hh7WakkelBZB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Przykładowy obraz z generatora przed treningiem."],"metadata":{"id":"PHyw987PfqEr"}},{"cell_type":"code","source":["generator = make_generator_model()\n","\n","noise = tf.random.normal([1, 100])\n","generated_image = generator(noise, training=False)\n","\n","plt.imshow(generated_image[0, :, :, 0])"],"metadata":{"id":"GB2DgDqClSle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dyskryminator: bierze jako wejście obraz i ocenia czy jest wygenerowany czy oryginalny - jedno wyjście."],"metadata":{"id":"ia6_5ovsftya"}},{"cell_type":"code","source":["def make_discriminator_model():\n","    model = tf.keras.Sequential()\n","    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n","                                     input_shape=[64,64, 3]))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n","    model.add(layers.LeakyReLU())\n","    model.add(layers.Dropout(0.3))\n","\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","\n","    return model"],"metadata":{"id":"avlUFsUslSqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator = make_discriminator_model()\n","decision = discriminator(generated_image)\n","print (decision)"],"metadata":{"id":"_9AXZnTQlStW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Poniższe komórki definiują funkcję straty dla modeli generatora i dyskryminatora"],"metadata":{"id":"_pdqqymbf6kr"}},{"cell_type":"code","source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"],"metadata":{"id":"bTGGsvnxlSy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    return total_loss"],"metadata":{"id":"szPJl2QJlYU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output)"],"metadata":{"id":"GIJBX8H-lYXw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator_optimizer = tf.keras.optimizers.Adam()\n","discriminator_optimizer = tf.keras.optimizers.Adam()"],"metadata":{"id":"cuDuvhDRlYdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)"],"metadata":{"id":"HfbnLZKblc2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ustawienie parametrów treningu\n","EPOCHS = 5\n","noise_dim = 100\n","num_examples_to_generate = 8\n","BATCH_SIZE = 64\n","\n","# ustawienie globalnego ziarna dla wszystkich losowych generacji\n","seed = tf.random.normal([num_examples_to_generate, noise_dim])"],"metadata":{"id":"4N1L87-jlc5F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defninicją pojedynczego kroku treningu modelu GAN:\n","- stworzenie szumu\n","- definicja obliczania gradientu z obiektem GradientTape\n","- generacja obrazu\n","- wywołanie dyskryminatora na obrazie generowanym i orginalnym\n","- wyznaczenie straty dla generatora i dyskryminatora\n","- obliczenie i aplikacja gradientów do wag sieci"],"metadata":{"id":"NKiM3YUHgR-c"}},{"cell_type":"code","source":["@tf.function\n","def train_step(images):\n","    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","      generated_images = generator(noise, training=True)\n","\n","      real_output = discriminator(images, training=True)\n","      fake_output = discriminator(generated_images, training=True)\n","\n","      gen_loss = generator_loss(fake_output)\n","      disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"],"metadata":{"id":"UYNSfLxTlc72"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definicja treningu modelu GAN"],"metadata":{"id":"fc36UkDsgv5R"}},{"cell_type":"code","source":["def train(dataset, epochs):\n","  for epoch in range(epochs):\n","    start = time.time()\n","\n","    for image_batch in dataset:\n","      train_step(image_batch)\n","\n","    # Save the model every 15 epochs\n","    if (epoch + 1) % 5 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n","\n","  # Generate after the final epoch\n","  display.clear_output(wait=True)\n","  generate_and_save_images(generator,\n","                           epochs,\n","                           seed)\n","  generator.save(\"final_model.keras\")\n"],"metadata":{"id":"4qnKU8VolYhf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Funkcja pomocnicza do generacji obrazów podczas treningu"],"metadata":{"id":"t3175a44gzGi"}},{"cell_type":"code","source":["def generate_and_save_images(model, epoch, test_input):\n","  predictions = model(test_input, training=False)\n","\n","  fig = plt.figure(figsize=(4, 4))\n","\n","  for i in range(predictions.shape[0]):\n","      plt.subplot(4, 4, i+1)\n","      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n","      plt.axis('off')\n","\n","  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n","  plt.show()"],"metadata":{"id":"3dlTQZWLlS2I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Trening sieci GAN. Może potrwać około 15 minut."],"metadata":{"id":"IQi09if8hEsb"}},{"cell_type":"code","source":["train(train_dataset, EPOCHS)"],"metadata":{"id":"fSjiu-z1k8-3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generacja przykładowego obrazu po treningu."],"metadata":{"id":"opp3RnLsiXza"}},{"cell_type":"code","source":["test_input = tf.random.normal([1, 100])\n","generated_image_after_training = generator(test_input, training=False)"],"metadata":{"id":"Zr1XEZ-plyVd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(generated_image_after_training[0, :, :, 0])"],"metadata":{"id":"NMLm8Yfldn_b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the saved model"],"metadata":{"id":"7rL9s42QpaKS"}},{"cell_type":"code","source":["model = keras.models.load_model(\"final_model.keras\")"],"metadata":{"id":"-8u418tSpecX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TASK** Zbudować sieć GAN dla danych fashion mnist:\n","- wczytać i przygotować dane do treningu\n","- zdefiniowac strukturę sieci GAN - dyksryminator i generator. **NOTE** Istotne jest dobranie odpowiednich kształtów poszczególnych warstw sieci, tak żeby odpowiadały kształtowi obrazków wejściowych (x,y, liczba kanałów)\n","- dobrać odpowiednią wielkość BATCH'a\n","- wytrenować model GAN\n","- wygenerować 5 obrazów z losowo wytworzonych danych wejściowych (random noise)"],"metadata":{"id":"PfbMXhpeZX9T"}},{"cell_type":"code","source":["(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"],"metadata":{"id":"leMZrq58aA6r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TASK** Uzupełnić poprawnie poniższą komórke do przygotowania danych do uczenia"],"metadata":{"id":"ayvf2AlBk5rs"}},{"cell_type":"code","source":["train_images = train_images.reshape(ilość danych, rozmiar obrazka oś x, rozmiar obrazka oś y, ilość kanałow).astype(zmiana na typ float32)"],"metadata":{"id":"6bFFeGw1kUAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BUFFER_SIZE = 60000\n","BATCH_SIZE = 256\n","train_images = # Znormalizować obrazy do zakresu [0, 1]"],"metadata":{"id":"g2dwW4tfkUFx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Stworzenie obiektu Dataset do treningu sieci GAN"],"metadata":{"id":"M1C1eKoVkU50"}},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"],"metadata":{"id":"Rj3_q7DbkULs"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"last_runtime":{"build_target":"//learning/deepmind/public/tools/ml_python:ml_notebook","kind":"private"},"private_outputs":true,"provenance":[{"file_id":"1U8RoTkLloMOVxLoXIsho1w5CMkFZ1Z-f","timestamp":1744373437277},{"file_id":"1cuoBSpWc0UNkLgMitqREBS0iGimAr-wd","timestamp":1743934636034},{"file_id":"https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb","timestamp":1743934021914}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}